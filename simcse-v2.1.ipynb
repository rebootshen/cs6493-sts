{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from abc import ABC\n",
    "from tqdm.notebook import tqdm\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Union, Optional, Dict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer,BertConfig  #, TrainingArguments, Trainer\n",
    "from transformers.trainer import Trainer,TrainingArguments\n",
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertModel\n",
    "from transformers.tokenization_utils_base import PaddingStrategy, PreTrainedTokenizerBase\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput, BaseModelOutputWithPoolingAndCrossAttentions\n",
    "import pickle\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Set path to SentEval\n",
    "PATH_TO_SENTEVAL = './SentEval'\n",
    "PATH_TO_DATA = './SentEval/data'\n",
    "\n",
    "# Import SentEval\n",
    "sys.path.insert(0, PATH_TO_SENTEVAL)\n",
    "import senteval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model in all STS tasks\n",
    "def print_table(task_names, scores):\n",
    "    tb = PrettyTable()\n",
    "    tb.field_names = task_names\n",
    "    tb.add_row(scores)\n",
    "    print(tb)\n",
    "    \n",
    "def evalModel(model,tokenizer, pooler): \n",
    "    tasks = ['STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']\n",
    "    \n",
    "    params = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 5}\n",
    "    params['classifier'] = {'nhid': 0, 'optim': 'rmsprop', 'batch_size': 128,\n",
    "                                'tenacity': 3, 'epoch_size': 2}\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def prepare(params, samples):\n",
    "        return\n",
    "\n",
    "    def batcher(params, batch, max_length=None):\n",
    "            # Handle rare token encoding issues in the dataset\n",
    "            if len(batch) >= 1 and len(batch[0]) >= 1 and isinstance(batch[0][0], bytes):\n",
    "                batch = [[word.decode('utf-8') for word in s] for s in batch]\n",
    "\n",
    "            sentences = [' '.join(s) for s in batch]\n",
    "            \n",
    "            batch = tokenizer.batch_encode_plus(\n",
    "                sentences,\n",
    "                return_tensors='pt',\n",
    "                padding=True,\n",
    "                max_length=max_length,\n",
    "                truncation=True\n",
    "            )\n",
    "            # Move to the correct device\n",
    "            for k in batch:\n",
    "                batch[k] = batch[k].to(device)\n",
    "            \n",
    "            # Get raw embeddings\n",
    "            with torch.no_grad():\n",
    "                pooler_output = model(**batch, output_hidden_states=True, return_dict=True)\n",
    "                if pooler == \"cls_before_pooler\":\n",
    "                    pooler_output = pooler_output.last_hidden_state[:, 0]\n",
    "                elif pooler == \"cls_after_pooler\":\n",
    "                    pooler_output = pooler_output.pooler_output\n",
    "\n",
    "            return pooler_output.cpu()\n",
    "    results = {}\n",
    "\n",
    "    for task in tasks:\n",
    "        se = senteval.engine.SE(params, batcher, prepare)\n",
    "        result = se.eval(task)\n",
    "        results[task] = result\n",
    "    task_names = []\n",
    "    scores = []\n",
    "    for task in ['STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']:\n",
    "        task_names.append(task)\n",
    "        if task in results:\n",
    "            if task in ['STS12', 'STS13', 'STS14', 'STS15', 'STS16']:\n",
    "                scores.append(\"%.2f\" % (results[task]['all']['spearman']['all'] * 100))\n",
    "            else:\n",
    "                scores.append(\"%.2f\" % (results[task]['test']['spearman'].correlation * 100))\n",
    "        else:\n",
    "            scores.append(\"0.00\")\n",
    "    task_names.append(\"Avg.\")\n",
    "    scores.append(\"%.2f\" % (sum([float(score) for score in scores]) / len(scores)))\n",
    "    print_table(task_names, scores)\n",
    "\n",
    "    return sum([float(score) for score in scores])/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataArguments:\n",
    "    train_file: str = field(default=\"./data/wiki1m_for_simcse.txt\",\n",
    "                            metadata={\n",
    "    \"help\": \"The path of train file\"})\n",
    "    model_name_or_path: str = field(default=\"bert-base-uncased\",\n",
    "                                    metadata={\n",
    "    \"help\": \"The name or path of pre-trained language model\"})\n",
    "    max_seq_length: int = field(default=32,\n",
    "                                metadata={\n",
    "    \"help\": \"The maximum total input sequence length after tokenization.\"})\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=\"trainer_models\",\n",
    "        num_train_epochs=1,\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size  = 64,\n",
    "        evaluation_strategy   = \"steps\",\n",
    "        eval_steps            = 125,\n",
    "        save_strategy = \"steps\",\n",
    "        save_steps=5000,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model = \"eval_avg_sts\",    \n",
    "        learning_rate=3e-5,\n",
    "        overwrite_output_dir=True,\n",
    "        do_train=True,\n",
    "        do_eval=False, \n",
    "        logging_steps=10)\n",
    "\n",
    "#The checkpoint save strategy to adopt during training.  KeyError: 'eval_loss'\n",
    "\n",
    "data_args = DataArguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fb7f57869c4e1d84f152b0838f15a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "YMCA in South Australia\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(data_args.model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, examples: List[str]):\n",
    "        total = len(examples)\n",
    "        # 将所有样本复制一份用于对比学习\n",
    "        sentences_pair = examples + examples\n",
    "        sent_features = tokenizer(sentences_pair,\n",
    "                                  max_length=data_args.max_seq_length,\n",
    "                                  truncation=True,\n",
    "                                  padding=False)\n",
    "        features = {\n",
    "    }\n",
    "        # 将相同的样本放在同一个列表中\n",
    "        for key in sent_features:\n",
    "            features[key] = [[sent_features[key][i], sent_features[key][i + total]] for i in tqdm(range(total))]\n",
    "        self.input_ids = features[\"input_ids\"]\n",
    "        self.attention_mask = features[\"attention_mask\"]\n",
    "        self.token_type_ids = features[\"token_type_ids\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "    \n",
    "            \"input_ids\": self.input_ids[item],\n",
    "            \"attention_mask\": self.attention_mask[item],\n",
    "            \"token_type_ids\": self.token_type_ids[item]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 26866, 1999, 2148, 2660, 102], [101, 26866, 1999, 2148, 2660, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]], 'token_type_ids': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]}\n",
      "1000000\n",
      "<class '__main__.PairDataset'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"./data/train_dataset\", \"rb\") as fp2:   # Unpickling\n",
    "    train_dataset = pickle.load(fp2)\n",
    "print(train_dataset[0])\n",
    "print(len(train_dataset))\n",
    "print(type(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 1996, 7328, 1997, 9569, 7490, 2964, 1010, 11295, 4676, 1998, 2969, 2128, 15204, 2102, 3754, 5171, 1997, 2049, 8759, 2018, 2445, 2019, 5020, 25691, 28126, 2000, 2148, 2827, 3241, 2013, 102], [101, 1996, 7328, 1997, 9569, 7490, 2964, 1010, 11295, 4676, 1998, 2969, 2128, 15204, 2102, 3754, 5171, 1997, 2049, 8759, 2018, 2445, 2019, 5020, 25691, 28126, 2000, 2148, 2827, 3241, 2013, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "#train_dataset = train_dataset1\n",
    "print(train_dataset[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollator:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, List[int]]]) -> Dict[str, torch.Tensor]:\n",
    "        special_keys = ['input_ids', 'attention_mask', 'token_type_ids']\n",
    "        batch_size = len(features)\n",
    "        if batch_size == 0:\n",
    "            return\n",
    "        # flat_features: [sen1, sen1, sen2, sen2, ...]\n",
    "        flat_features = []\n",
    "        for feature in features:\n",
    "            for i in range(2):\n",
    "                flat_features.append({\n",
    "    k: feature[k][i] for k in feature.keys() if k in special_keys})\n",
    "        # padding\n",
    "        batch = self.tokenizer.pad(\n",
    "            flat_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        # batch_size, 2, seq_len\n",
    "        batch = {\n",
    "    k: batch[k].view(batch_size, 2, -1) for k in batch if k in special_keys}\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'token_type_ids'])\n",
      "torch.Size([64, 2, 32])\n"
     ]
    }
   ],
   "source": [
    "collate_fn = DataCollator(tokenizer)\n",
    "\n",
    "\n",
    "#dataloader = DataLoader(train_dataset, batch_size=4, collate_fn=collate_fn)\n",
    "dataloader = DataLoader(train_dataset, batch_size=64, collate_fn=collate_fn)\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "print(batch.keys())\n",
    "print(batch[\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForCL: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForCL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForCL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForCL were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['mlp.dense.weight', 'mlp.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['loss', 'logits'])\n"
     ]
    }
   ],
   "source": [
    "# 全连接层，用于投影CLS的向量表示\n",
    "class MLPLayer(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_size, output_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = self.dense(features)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "# 相似度层，计算向量间相似度\n",
    "class Similarity(nn.Module):\n",
    "    def __init__(self, temp):\n",
    "        super().__init__()\n",
    "        self.temp = temp\n",
    "        self.cos = nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return self.cos(x, y) / self.temp\n",
    "\n",
    "    \n",
    "# SimCSE的完整模型结构\n",
    "class BertForCL(BertPreTrainedModel, ABC):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.mlp = MLPLayer(config.hidden_size, config.hidden_size)\n",
    "        self.sim = Similarity(temp=0.05)\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids=None,\n",
    "                attention_mask=None,\n",
    "                token_type_ids=None,\n",
    "                position_ids=None,\n",
    "                head_mask=None,\n",
    "                inputs_embeds=None,\n",
    "                labels=None,\n",
    "                output_attentions=None,\n",
    "                output_hidden_states=None,\n",
    "                return_dict=None,\n",
    "                sent_emb=False):\n",
    "        if sent_emb:\n",
    "            # 模型推断时使用的forward\n",
    "            return self.sentemb_forward(input_ids=input_ids,\n",
    "                                        attention_mask=attention_mask,\n",
    "                                        token_type_ids=token_type_ids,\n",
    "                                        position_ids=position_ids,\n",
    "                                        head_mask=head_mask,\n",
    "                                        inputs_embeds=inputs_embeds,\n",
    "                                        labels=labels,\n",
    "                                        output_attentions=output_attentions,\n",
    "                                        output_hidden_states=output_hidden_states,\n",
    "                                        return_dict=return_dict)\n",
    "        else:\n",
    "            # 模型训练时使用的forward\n",
    "            return self.cl_forward(input_ids=input_ids,\n",
    "                                   attention_mask=attention_mask,\n",
    "                                   token_type_ids=token_type_ids,\n",
    "                                   position_ids=position_ids,\n",
    "                                   head_mask=head_mask,\n",
    "                                   inputs_embeds=inputs_embeds,\n",
    "                                   labels=labels,\n",
    "                                   output_attentions=output_attentions,\n",
    "                                   output_hidden_states=output_hidden_states,\n",
    "                                   return_dict=return_dict)\n",
    "\n",
    "    def sentemb_forward(self,\n",
    "                        input_ids=None,\n",
    "                        attention_mask=None,\n",
    "                        token_type_ids=None,\n",
    "                        position_ids=None,\n",
    "                        head_mask=None,\n",
    "                        inputs_embeds=None,\n",
    "                        labels=None,\n",
    "                        output_attentions=None,\n",
    "                        output_hidden_states=None,\n",
    "                        return_dict=None):\n",
    "        # 1.使用bert进行编码\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        # 2.取cls的表示\n",
    "        cls_output = outputs.last_hidden_state[:, 0]\n",
    "        # 3.使用MLP进行投影\n",
    "        cls_output = self.mlp(cls_output)\n",
    "        # 返回\n",
    "        if not return_dict:\n",
    "            return (outputs[0], cls_output) + outputs[2:]\n",
    "\n",
    "        return BaseModelOutputWithPoolingAndCrossAttentions(\n",
    "            pooler_output=cls_output,\n",
    "            last_hidden_state=outputs.last_hidden_state,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "        )\n",
    "\n",
    "    def cl_forward(self,\n",
    "                   input_ids=None,\n",
    "                   attention_mask=None,\n",
    "                   token_type_ids=None,\n",
    "                   position_ids=None,\n",
    "                   head_mask=None,\n",
    "                   inputs_embeds=None,\n",
    "                   labels=None,\n",
    "                   output_attentions=None,\n",
    "                   output_hidden_states=None,\n",
    "                   return_dict=None):\n",
    "        # input_ids: batch_size, num_sent, len\n",
    "        batch_size = input_ids.size(0)\n",
    "        num_sent = input_ids.size(1)  # 2\n",
    "        # 1. 重塑输入张量的形状，使其满足bert对输入的要求\n",
    "        # input_ids: batch_size * num_sent, len\n",
    "        input_ids = input_ids.view((-1, input_ids.size(-1)))\n",
    "        attention_mask = attention_mask.view((-1, attention_mask.size(-1)))\n",
    "        # 2. 使用bert进行编码\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        # 3. 取cls的向量表示\n",
    "        cls_output = outputs.last_hidden_state[:, 0]\n",
    "        # 4. 重塑形状\n",
    "        cls_output = cls_output.view((batch_size, num_sent, cls_output.size(-1)))\n",
    "        # 5. 全连接层投影\n",
    "        # batch_size, num_sent, 768\n",
    "        cls_output = self.mlp(cls_output)\n",
    "        # 6. 将同一批样本的两次向量表示分开\n",
    "        z1, z2 = cls_output[:, 0], cls_output[:, 1]\n",
    "        # 7. 计算两两相似度，得到相似度矩阵cos_sim\n",
    "        cos_sim = self.sim(z1.unsqueeze(1), z2.unsqueeze(0))\n",
    "        # 8. 生成标签[0,1,...,batch_size-1]，该标签用于提高相似度句子cos_sim对角线，并降低非对角线\n",
    "        labels = torch.arange(cos_sim.size(0)).long().to(self.device)\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(cos_sim, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (cos_sim,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=cos_sim,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "model = BertForCL.from_pretrained(data_args.model_name_or_path)\n",
    "cl_out = model(**batch, return_dict=True)\n",
    "print(cl_out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# override the evaluate method\n",
    "class SimCSETrainer(Trainer):\n",
    "    def __init__(self,**paraments):\n",
    "        super().__init__(**paraments)\n",
    "        \n",
    "        self.best_sts = 0.0\n",
    "        \n",
    "    def evaluate(\n",
    "        self,\n",
    "        eval_dataset: Optional[Dataset] = None,\n",
    "        ignore_keys: Optional[List[str]] = None,\n",
    "        metric_key_prefix: str = \"eval\",\n",
    "        eval_senteval_transfer: bool = False,\n",
    "    ) -> Dict[str, float]:\n",
    "\n",
    "        # SentEval prepare and batcher\n",
    "        def prepare(params, samples):\n",
    "            return\n",
    "\n",
    "        def batcher(params, batch):\n",
    "            sentences = [' '.join(s) for s in batch]\n",
    "            batch = self.tokenizer.batch_encode_plus(\n",
    "                sentences,\n",
    "                return_tensors='pt',\n",
    "                padding=True,\n",
    "            )\n",
    "            for k in batch:\n",
    "                batch[k] = batch[k].to(self.args.device)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**batch, output_hidden_states=True, return_dict=True, sent_emb=True)\n",
    "                pooler_output = outputs.last_hidden_state[:, 0]\n",
    "            return pooler_output.cpu()\n",
    "\n",
    "        # Set params for SentEval (fastmode)\n",
    "        params = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 5}\n",
    "        params['classifier'] = {'nhid': 0, 'optim': 'rmsprop', 'batch_size': 128,\n",
    "                                            'tenacity': 3, 'epoch_size': 2}\n",
    "\n",
    "        se = senteval.engine.SE(params, batcher, prepare)\n",
    "        tasks = ['STSBenchmark', 'SICKRelatedness']\n",
    "        self.model.eval()\n",
    "        results = se.eval(tasks)\n",
    "        \n",
    "        stsb_spearman = results['STSBenchmark']['dev']['spearman'][0]\n",
    "        sickr_spearman = results['SICKRelatedness']['dev']['spearman'][0]\n",
    "\n",
    "        metrics = {\"eval_stsb_spearman\": stsb_spearman, \"eval_sickr_spearman\": sickr_spearman, \"eval_avg_sts\": (stsb_spearman + sickr_spearman) / 2} \n",
    "        print(metrics)\n",
    "        \n",
    "        # save and eval model\n",
    "        if metrics[\"eval_avg_sts\"]>self.best_sts:\n",
    "            self.best_sts = metrics[\"eval_avg_sts\"]\n",
    "            evalModel(self.model.bert,tokenizer, pooler = 'cls_before_pooler')\n",
    "            self.save_model(self.args.output_dir+\"/best-model\")\n",
    "            \n",
    "        self.log(metrics)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))\n",
    "trainer = SimCSETrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the evaluate method and see what are the initial results\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2396' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2396/15625 24:59:15 < 138:04:43, 0.03 it/s, Epoch 0.15/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_stsb_spearman': 0.6067437923858473, 'eval_sickr_spearman': 0.6164602627042094, 'eval_avg_sts': 0.6116020275450283}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./SentEval\\senteval\\sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "./SentEval\\senteval\\sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n",
      "Saving model checkpoint to trainer_models/best-model\n",
      "Configuration saved in trainer_models/best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 38.88 | 67.18 | 52.60 | 63.76 | 68.23 |    48.51     |      59.82      | 57.00 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainer_models/best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in trainer_models/best-model\\tokenizer_config.json\n",
      "Special tokens file saved in trainer_models/best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_stsb_spearman': 0.6556748777551351, 'eval_sickr_spearman': 0.6446393894514284, 'eval_avg_sts': 0.6501571336032818}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to trainer_models/best-model\n",
      "Configuration saved in trainer_models/best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 48.07 | 71.27 | 58.53 | 68.05 | 70.83 |    55.97     |      63.13      | 62.26 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainer_models/best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in trainer_models/best-model\\tokenizer_config.json\n",
      "Special tokens file saved in trainer_models/best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_stsb_spearman': 0.6778662596176872, 'eval_sickr_spearman': 0.6640503906000187, 'eval_avg_sts': 0.6709583251088529}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to trainer_models/best-model\n",
      "Configuration saved in trainer_models/best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 50.57 | 70.86 | 59.40 | 69.27 | 72.26 |    58.64     |      64.93      | 63.70 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainer_models/best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in trainer_models/best-model\\tokenizer_config.json\n",
      "Special tokens file saved in trainer_models/best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_stsb_spearman': 0.7043979327317484, 'eval_sickr_spearman': 0.6932258264843686, 'eval_avg_sts': 0.6988118796080585}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to trainer_models/best-model\n",
      "Configuration saved in trainer_models/best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 54.33 | 73.94 | 64.35 | 71.86 | 73.91 |    63.14     |      67.96      | 67.07 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainer_models/best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in trainer_models/best-model\\tokenizer_config.json\n",
      "Special tokens file saved in trainer_models/best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_stsb_spearman': 0.7266398199672333, 'eval_sickr_spearman': 0.7048700544371117, 'eval_avg_sts': 0.7157549372021725}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to trainer_models/best-model\n",
      "Configuration saved in trainer_models/best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 57.77 | 75.56 | 65.75 | 73.29 | 75.23 |    65.91     |      69.08      | 68.94 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainer_models/best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in trainer_models/best-model\\tokenizer_config.json\n",
      "Special tokens file saved in trainer_models/best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_stsb_spearman': 0.7105451166892882, 'eval_sickr_spearman': 0.683240928993008, 'eval_avg_sts': 0.6968930228411481}\n",
      "{'eval_stsb_spearman': 0.7428545357835161, 'eval_sickr_spearman': 0.7094027494798264, 'eval_avg_sts': 0.7261286426316713}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to trainer_models/best-model\n",
      "Configuration saved in trainer_models/best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 60.82 | 74.07 | 66.00 | 74.78 | 74.65 |    68.77     |      69.11      | 69.74 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainer_models/best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in trainer_models/best-model\\tokenizer_config.json\n",
      "Special tokens file saved in trainer_models/best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_stsb_spearman': 0.7726937716783824, 'eval_sickr_spearman': 0.7331302576835583, 'eval_avg_sts': 0.7529120146809704}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to trainer_models/best-model\n",
      "Configuration saved in trainer_models/best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 64.84 | 76.84 | 68.43 | 76.44 | 75.54 |    72.62     |      70.42      | 72.16 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainer_models/best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in trainer_models/best-model\\tokenizer_config.json\n",
      "Special tokens file saved in trainer_models/best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_stsb_spearman': 0.7486347815411812, 'eval_sickr_spearman': 0.7146747392358765, 'eval_avg_sts': 0.7316547603885288}\n",
      "{'eval_stsb_spearman': 0.7784627187200925, 'eval_sickr_spearman': 0.7296869080214601, 'eval_avg_sts': 0.7540748133707763}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to trainer_models/best-model\n",
      "Configuration saved in trainer_models/best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 63.34 | 75.32 | 67.93 | 75.72 | 75.04 |    71.89     |      70.29      | 71.36 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainer_models/best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in trainer_models/best-model\\tokenizer_config.json\n",
      "Special tokens file saved in trainer_models/best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_stsb_spearman': 0.7700349958221805, 'eval_sickr_spearman': 0.7234236523939301, 'eval_avg_sts': 0.7467293241080553}\n",
      "{'eval_stsb_spearman': 0.7879093462357525, 'eval_sickr_spearman': 0.7335063412078187, 'eval_avg_sts': 0.7607078437217856}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to trainer_models/best-model\n",
      "Configuration saved in trainer_models/best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 65.24 | 77.23 | 69.23 | 76.93 | 75.82 |    73.33     |      70.75      | 72.65 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainer_models/best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in trainer_models/best-model\\tokenizer_config.json\n",
      "Special tokens file saved in trainer_models/best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_stsb_spearman': 0.789669769158824, 'eval_sickr_spearman': 0.7337157087789875, 'eval_avg_sts': 0.7616927389689058}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to trainer_models/best-model\n",
      "Configuration saved in trainer_models/best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 65.75 | 77.27 | 69.41 | 77.14 | 76.02 |    73.65     |      70.87      | 72.87 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainer_models/best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in trainer_models/best-model\\tokenizer_config.json\n",
      "Special tokens file saved in trainer_models/best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_stsb_spearman': 0.7897522620983157, 'eval_sickr_spearman': 0.731617422081562, 'eval_avg_sts': 0.7606848420899388}\n",
      "{'eval_stsb_spearman': 0.7870369417191059, 'eval_sickr_spearman': 0.7312557959188345, 'eval_avg_sts': 0.7591463688189701}\n",
      "{'eval_stsb_spearman': 0.7939875870852156, 'eval_sickr_spearman': 0.7275318005310333, 'eval_avg_sts': 0.7607596938081245}\n",
      "{'eval_stsb_spearman': 0.7946882512698189, 'eval_sickr_spearman': 0.7240421488871488, 'eval_avg_sts': 0.7593652000784838}\n",
      "{'eval_stsb_spearman': 0.775676336014262, 'eval_sickr_spearman': 0.7115506523050373, 'eval_avg_sts': 0.7436134941596497}\n",
      "{'eval_stsb_spearman': 0.8075344345123314, 'eval_sickr_spearman': 0.7345890582964367, 'eval_avg_sts': 0.7710617464043841}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to trainer_models/best-model\n",
      "Configuration saved in trainer_models/best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.14 | 81.76 | 73.64 | 80.65 | 78.37 |    76.39     |      71.68      | 75.95 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainer_models/best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in trainer_models/best-model\\tokenizer_config.json\n",
      "Special tokens file saved in trainer_models/best-model\\special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"trainer_models/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = BertConfig()\n",
    "\n",
    "#model = SimCSEModel(config).from_pretrained(\"trainer_models/best-model\").to(device)\n",
    "model = BertForCL(config).from_pretrained(\"trainer_models/best-model\").to(device)\n",
    "\n",
    "avg = evalModel(model.bert,tokenizer, pooler = 'cls_before_pooler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
